#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import argparse
import requests
import time

DNS_BATCH_SIZE = 800  # æ¯æ‰¹éªŒè¯æ•°é‡
TOTAL_PARTS = 16
URLS_FILE = 'urls.txt'
TMP_DIR = 'tmp'
DIST_DIR = 'dist'

os.makedirs(TMP_DIR, exist_ok=True)
os.makedirs(DIST_DIR, exist_ok=True)

def update_urls():
    """æ¯å¤©æ›´æ–° urls.txt"""
    url_source = 'https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/dist/blocklist.txt'
    r = requests.get(url_source)
    r.raise_for_status()
    with open(URLS_FILE, 'w', encoding='utf-8') as f:
        f.write(r.text)
    print(f"ðŸ“„ æ›´æ–° urls.txt æˆåŠŸï¼Œè§„åˆ™æ€»æ•°: {len(r.text.splitlines())}")

def load_rules():
    with open(URLS_FILE, 'r', encoding='utf-8') as f:
        rules = [line.strip() for line in f if line.strip()]
    return rules

def split_rules(rules):
    """åˆ†æˆ16ä¸ªåˆ‡ç‰‡"""
    part_size = (len(rules) + TOTAL_PARTS - 1) // TOTAL_PARTS
    parts = []
    for i in range(TOTAL_PARTS):
        start = i * part_size
        end = start + part_size
        part = rules[start:end]
        parts.append(part)
        part_file = os.path.join(TMP_DIR, f'part_{i+1:02d}.txt')
        with open(part_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(part))
        print(f"ðŸ“„ åˆ†ç‰‡ {i+1} ä¿å­˜ {len(part)} æ¡è§„åˆ™ â†’ {part_file}")
        print(f"å‰ 10 æ¡ç¤ºä¾‹ï¼š {part[:10]}")
    return parts

def validate_rules(part_rules):
    """æ¨¡æ‹ŸéªŒè¯ï¼Œè¿”å›žæœ‰æ•ˆè§„åˆ™åˆ—è¡¨"""
    valid_rules = []
    total = len(part_rules)
    for i in range(0, total, DNS_BATCH_SIZE):
        batch = part_rules[i:i+DNS_BATCH_SIZE]
        # æ¨¡æ‹Ÿ DNS éªŒè¯ï¼Œè¿™é‡Œç›´æŽ¥å‡è®¾å¶æ•°æ¡æœ‰æ•ˆ
        batch_valid = [rule for idx, rule in enumerate(batch) if idx % 2 == 0]
        valid_rules.extend(batch_valid)
        print(f"â± å·²éªŒè¯ {min(i+DNS_BATCH_SIZE, total)}/{total} æ¡ï¼Œæœ¬æ‰¹æœ‰æ•ˆ {len(batch_valid)} æ¡")
        time.sleep(0.1)  # æ¨¡æ‹ŸéªŒè¯è€—æ—¶
    return valid_rules

def save_valid_rules(valid_rules):
    out_file = os.path.join(DIST_DIR, 'blocklist_valid.txt')
    with open(out_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(valid_rules))
    print(f"âœ… å·²ä¿å­˜æœ‰æ•ˆè§„åˆ™ï¼Œå…± {len(valid_rules)} æ¡ â†’ {out_file}")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--part', type=int, default=-1, help='æŒ‡å®šéªŒè¯çš„åˆ‡ç‰‡ç¼–å· 0-15')
    args = parser.parse_args()

    # æ¯å¤©æ›´æ–° urls.txt
    if not os.path.exists(URLS_FILE) or time.time() - os.path.getmtime(URLS_FILE) > 86400:
        update_urls()

    rules = load_rules()
    parts = split_rules(rules)

    if 0 <= args.part < TOTAL_PARTS:
        # æ‰‹åŠ¨è§¦å‘éªŒè¯å•ä¸ªåˆ‡ç‰‡
        part_idx = args.part
        print(f"â± å½“å‰å¤„ç†åˆ†ç‰‡ï¼štmp/part_{part_idx+1:02d}.txt, æ€»è§„åˆ™ {len(parts[part_idx])} æ¡")
        print(f"å‰ 10 æ¡è§„åˆ™ç¤ºä¾‹ï¼š {parts[part_idx][:10]}")
        valid_rules = validate_rules(parts[part_idx])
    else:
        # è‡ªåŠ¨è½®æ›¿ï¼ŒæŒ‰é¡ºåºéªŒè¯æ¯ä¸ªåˆ‡ç‰‡
        valid_rules = []
        for idx, part in enumerate(parts):
            print(f"â± å½“å‰å¤„ç†åˆ†ç‰‡ï¼štmp/part_{idx+1:02d}.txt, æ€»è§„åˆ™ {len(part)} æ¡")
            print(f"å‰ 10 æ¡è§„åˆ™ç¤ºä¾‹ï¼š {part[:10]}")
            valid_rules.extend(validate_rules(part))

    save_valid_rules(valid_rules)

if __name__ == '__main__':
    main()
