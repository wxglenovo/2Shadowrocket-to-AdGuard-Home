DNS_BATCH_SIZE = 800
PARTS = 16
MAX_WORKERS = 80

# çœç•¥ä¸‹è½½ urls.txtã€å»æ³¨é‡Šã€å»é‡ã€åˆ‡åˆ†ç­‰é€»è¾‘

def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--part', type=int, help='æ‰‹åŠ¨æŒ‡å®šåˆ†ç‰‡ 0~15')
    args = parser.parse_args()

    # è®¡ç®—å½“å‰åˆ†ç‰‡
    if args.part is not None:
        part_index = args.part
    else:
        from datetime import datetime
        minute = datetime.utcnow().hour * 60 + datetime.utcnow().minute
        part_index = (minute // 90) % PARTS

    target_file = f"tmp/part_{part_index:02d}.txt"
    print(f"ğŸ“„ å½“å‰å¤„ç†åˆ†ç‰‡ï¼š{target_file}")
    
    # è¯»å–è§„åˆ™
    with open(target_file, "r", encoding="utf-8") as f:
        rules = f.read().splitlines()
    print(f"â± æ€»è§„åˆ™ {len(rules):,} æ¡")
    print(f"å‰ 10 æ¡è§„åˆ™ç¤ºä¾‹ï¼š {rules[:10]}")

    # DNS éªŒè¯
    import concurrent.futures
    valid = []
    def check_batch(batch):
        batch_valid = []
        import dns.resolver
        resolver = dns.resolver.Resolver()
        resolver.timeout = 1.5
        resolver.lifetime = 1.5
        resolver.nameservers = ["1.1.1.1","8.8.8.8","9.9.9.9"]
        for rule in batch:
            domain = rule.lstrip('|').lstrip('.').split('^')[0]
            try:
                resolver.resolve(domain, 'A')
                batch_valid.append(rule)
            except:
                continue
        return batch_valid

    batches = [rules[i:i+DNS_BATCH_SIZE] for i in range(0,len(rules),DNS_BATCH_SIZE)]
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        for i, result in enumerate(ex.map(check_batch, batches), 1):
            valid.extend(result)
            print(f"âœ… å·²éªŒè¯ {min(i*DNS_BATCH_SIZE,len(rules)):,}/{len(rules):,} æ¡ï¼Œæœ¬æ‰¹æœ‰æ•ˆ {len(result):,} æ¡")

    # ä¿å­˜æœ‰æ•ˆè§„åˆ™
    import os
    os.makedirs("dist", exist_ok=True)
    with open("dist/blocklist_valid.txt", "a", encoding="utf-8") as f:
        f.write("\n".join(valid)+"\n")
