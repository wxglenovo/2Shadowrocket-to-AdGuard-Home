import os
import requests
import dns.resolver
import concurrent.futures
from datetime import datetime
import argparse

# ---------------------------
# é…ç½®
# ---------------------------
URLS_FILE = "urls.txt"
DIST_DIR = "dist"
TMP_DIR = "tmp"
PARTS = 16
DNS_BATCH_SIZE = 800
MAX_WORKERS = 80  # DNS å¹¶å‘çº¿ç¨‹æ•°

resolver = dns.resolver.Resolver()
resolver.timeout = 1.5
resolver.lifetime = 1.5
resolver.nameservers = ["1.1.1.1", "8.8.8.8", "9.9.9.9"]

# ---------------------------
# å‡½æ•°
# ---------------------------
def safe_fetch(url):
    try:
        r = requests.get(url, timeout=10)
        r.raise_for_status()
        return r.text.splitlines()
    except:
        return []

def clean_rule(line):
    l = line.strip()
    if not l or l.startswith("#"):
        return None
    return l

def extract_domain(rule):
    d = rule.lstrip("|").lstrip(".").split("^")[0]
    return d.strip()

def is_valid_domain(domain):
    try:
        resolver.resolve(domain, "A")
        return True
    except:
        return False

def check_rule(rule):
    domain = extract_domain(rule)
    return rule if is_valid_domain(domain) else None

# ---------------------------
# ä¸»å‡½æ•°
# ---------------------------
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--part", type=int, default=-1, help="æ‰‹åŠ¨éªŒè¯æŒ‡å®šåˆ†ç‰‡ï¼ˆ0~15ï¼‰")
    args = parser.parse_args()
    part_arg = args.part

    os.makedirs(DIST_DIR, exist_ok=True)
    os.makedirs(TMP_DIR, exist_ok=True)
    part_files = [os.path.join(TMP_DIR, f"part_{i+1:02}.txt") for i in range(PARTS)]
    valid_output = os.path.join(DIST_DIR, "blocklist_valid.txt")

    # ---------------------------
    # å¦‚æœä¸å­˜åœ¨åˆ†ç‰‡æˆ– urls.txt æ›´æ–°æ—¶é—´å¤§äºä¸€å¤©ï¼Œåˆ™æ›´æ–° urls.txt å¹¶åˆ‡åˆ†
    # ---------------------------
    need_update = False
    if not os.path.exists(URLS_FILE):
        need_update = True
    else:
        mtime = datetime.fromtimestamp(os.path.getmtime(URLS_FILE))
        if (datetime.utcnow() - mtime).days >= 1:
            need_update = True

    if need_update:
        print("ğŸŸ¢ æ›´æ–° urls.txt å¹¶åˆ‡ç‰‡")
        with open(URLS_FILE, "r", encoding="utf-8") as f:
            urls = [x.strip() for x in f if x.strip() and not x.startswith("#")]

        all_rules = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=20) as ex:
            for lines in ex.map(safe_fetch, urls):
                all_rules.extend(lines)

        cleaned = list(dict.fromkeys([clean_rule(x) for x in all_rules if clean_rule(x)]))
        total = len(cleaned)
        print(f"âœ… æ€»è®¡å»é‡è§„åˆ™ {total:,} æ¡")

        chunk = total // PARTS
        for idx in range(PARTS):
            start = idx * chunk
            end = None if idx == PARTS - 1 else (idx + 1) * chunk
            with open(part_files[idx], "w", encoding="utf-8") as f:
                f.write("\n".join(cleaned[start:end]))
            print(f"ğŸ“„ åˆ†ç‰‡ {idx+1} ä¿å­˜ {len(cleaned[start:end]):,} æ¡è§„åˆ™ â†’ {part_files[idx]}")
    else:
        print("ğŸŸ¢ urls.txt å½“å¤©å·²æ›´æ–°ï¼Œæ— éœ€é‡å¤ä¸‹è½½")

    # ---------------------------
    # ç¡®å®šè¦éªŒè¯çš„åˆ†ç‰‡
    # ---------------------------
    if part_arg >= 0 and part_arg < PARTS:
        target_idx = part_arg
    else:
        # è‡ªåŠ¨è½®æ›¿ï¼Œæ¯ 1.5 å°æ—¶å¤„ç†ä¸€ä¸ªåˆ†ç‰‡
        minute = datetime.utcnow().hour * 60 + datetime.utcnow().minute
        target_idx = (minute // 90) % PARTS

    target_file = part_files[target_idx]
    if not os.path.exists(target_file):
        print(f"âš ï¸ åˆ†ç‰‡ä¸å­˜åœ¨ï¼š{target_file}")
        return

    with open(target_file, "r", encoding="utf-8") as f:
        rules = f.read().splitlines()
    print(f"â± å½“å‰å¤„ç†åˆ†ç‰‡ï¼š{target_file}, æ€»è§„åˆ™ {len(rules):,} æ¡")
    print(f"å‰ 10 æ¡è§„åˆ™ç¤ºä¾‹ï¼š {rules[:10]}")

    # ---------------------------
    # DNS éªŒè¯
    # ---------------------------
    valid = []
    total_rules = len(rules)
    for i in range(0, total_rules, DNS_BATCH_SIZE):
        batch = rules[i:i+DNS_BATCH_SIZE]
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
            results = list(ex.map(check_rule, batch))
        batch_valid = [r for r in results if r]
        valid.extend(batch_valid)
        print(f"âœ… å·²éªŒè¯ {min(i+DNS_BATCH_SIZE, total_rules):,}/{total_rules:,} æ¡ï¼Œæœ¬æ‰¹æœ‰æ•ˆ {len(batch_valid):,} æ¡")

    with open(valid_output, "a", encoding="utf-8") as f:
        f.write("\n".join(valid) + "\n")
    print(f"ğŸ¯ æœ¬æ¬¡åˆ†ç‰‡æœ‰æ•ˆ {len(valid):,} æ¡ â†’ å·²è¿½åŠ è‡³ {valid_output}")
    print("âœ… æ‰§è¡Œç»“æŸ")

if __name__ == "__main__":
    main()
