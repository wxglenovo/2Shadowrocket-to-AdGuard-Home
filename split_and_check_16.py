#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import argparse
import requests
from pathlib import Path

DNS_BATCH_SIZE = 800  # æ¯æ‰¹å¤„ç†æ¡æ•°

# ===============================
# å‚æ•°è§£æ
# ===============================
parser = argparse.ArgumentParser(description="DNS åˆ†ç‰‡éªŒè¯è„šæœ¬")
parser.add_argument('--part', type=int, help='æŒ‡å®šéªŒè¯åˆ†ç‰‡ 1~16', default=None)
args = parser.parse_args()

# ===============================
# æ–‡ä»¶ä¸ç›®å½•å‡†å¤‡
# ===============================
urls_file = Path("urls.txt")
tmp_dir = Path("tmp")
dist_dir = Path("dist")
tmp_dir.mkdir(exist_ok=True)
dist_dir.mkdir(exist_ok=True)

# ===============================
# è¯»å– urls.txt
# ===============================
if not urls_file.exists():
    raise FileNotFoundError(f"{urls_file} ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ›´æ–°")

with open(urls_file, 'r', encoding='utf-8') as f:
    urls = [line.strip() for line in f if line.strip()]

total_count = len(urls)

# ===============================
# åˆ‡åˆ†ä¸º 16 ä¸ªåˆ†ç‰‡
# ===============================
parts = 16
part_size = (total_count + parts - 1) // parts  # å‘ä¸Šå–æ•´

part_files = []
for i in range(parts):
    start = i * part_size
    end = min(start + part_size, total_count)
    part_urls = urls[start:end]
    part_file = tmp_dir / f"part_{i+1:02d}.txt"
    with open(part_file, 'w', encoding='utf-8') as f:
        f.write("\n".join(part_urls))
    print(f"ğŸ“„ åˆ†ç‰‡ {i+1} ä¿å­˜ {len(part_urls)} æ¡è§„åˆ™ â†’ {part_file}")
    print("å‰ 10 æ¡ç¤ºä¾‹ï¼š", part_urls[:10])
    part_files.append(part_file)

# ===============================
# éªŒè¯å‡½æ•°ï¼ˆç¤ºä¾‹ï¼šè¯·æ±‚æ¯æ¡ URL è¿”å›çŠ¶æ€ç  200ï¼‰
# ===============================
def validate_dns(url_list):
    valid = []
    for i in range(0, len(url_list), DNS_BATCH_SIZE):
        batch = url_list[i:i+DNS_BATCH_SIZE]
        batch_valid = []
        for u in batch:
            try:
                # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…å¯ä»¥åš DNS æŸ¥è¯¢æˆ–è¯·æ±‚å¤´éªŒè¯
                resp = requests.head("http://" + u.lstrip("|^").replace(".*", ""), timeout=3)
                if resp.status_code < 400:
                    batch_valid.append(u)
            except:
                pass
        valid.extend(batch_valid)
        print(f"âœ… å·²éªŒè¯ {min(i+DNS_BATCH_SIZE, len(url_list))}/{len(url_list)} æ¡ï¼Œæœ¬æ‰¹æœ‰æ•ˆ {len(batch_valid)} æ¡")
    return valid

# ===============================
# è‡ªåŠ¨æˆ–æ‰‹åŠ¨åˆ†ç‰‡éªŒè¯
# ===============================
if args.part:
    part_index = args.part - 1
    if part_index < 0 or part_index >= parts:
        raise ValueError("åˆ†ç‰‡ç¼–å·å¿…é¡» 1~16")
    current_part_file = part_files[part_index]
    print(f"â± å½“å‰å¤„ç†åˆ†ç‰‡ï¼š{current_part_file}, æ€»è§„åˆ™ {len(open(current_part_file).readlines())} æ¡")
    with open(current_part_file, 'r', encoding='utf-8') as f:
        urls_to_check = [line.strip() for line in f if line.strip()]
    valid_urls = validate_dns(urls_to_check)
else:
    # è‡ªåŠ¨è½®æ›¿éªŒè¯å…¨éƒ¨åˆ†ç‰‡ï¼ˆæŒ‰é¡ºåºå¤„ç†ï¼‰
    for idx, part_file in enumerate(part_files):
        print(f"â± å½“å‰å¤„ç†åˆ†ç‰‡ {idx+1}: {part_file}, æ€»è§„åˆ™ {len(open(part_file).readlines())} æ¡")
        with open(part_file, 'r', encoding='utf-8') as f:
            urls_to_check = [line.strip() for line in f if line.strip()]
        valid_urls = validate_dns(urls_to_check)

# ===============================
# ä¿å­˜æœ€ç»ˆæœ‰æ•ˆè§„åˆ™
# ===============================
valid_file = dist_dir / "blocklist_valid.txt"
with open(valid_file, 'w', encoding='utf-8') as f:
    f.write("\n".join(valid_urls))
print(f"ğŸ¯ æœ€ç»ˆæœ‰æ•ˆè§„åˆ™ä¿å­˜åˆ° {valid_file}, å…± {len(valid_urls)} æ¡")
