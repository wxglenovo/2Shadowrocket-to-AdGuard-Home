#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import argparse
import requests
import dns.resolver
from datetime import datetime

# é…ç½®
URLS_TXT = "urls.txt"
TMP_DIR = "tmp"
DIST_DIR = "dist"
DNS_BATCH_SIZE = 800
NUM_PARTS = 16

os.makedirs(TMP_DIR, exist_ok=True)
os.makedirs(DIST_DIR, exist_ok=True)

def download_urls():
    print("ğŸ“¥ ä¸‹è½½ urls.txt ...")
    url = "https://raw.githubusercontent.com/your-repo/urls.txt"  # æ›¿æ¢ä¸ºä½ çš„æº
    r = requests.get(url)
    r.raise_for_status()
    with open(URLS_TXT, "w", encoding="utf-8") as f:
        f.write(r.text)
    print(f"âœ… ä¸‹è½½å®Œæˆï¼Œå…± {len(r.text.splitlines())} æ¡è§„åˆ™")
    return r.text.splitlines()

def split_urls(lines):
    total = len(lines)
    part_size = total // NUM_PARTS + 1
    part_files = []
    for i in range(NUM_PARTS):
        part_lines = lines[i*part_size:(i+1)*part_size]
        part_file = os.path.join(TMP_DIR, f"part_{i+1:02}.txt")
        with open(part_file, "w", encoding="utf-8") as f:
            f.write("\n".join(part_lines))
        print(f"ğŸ“„ åˆ†ç‰‡ {i+1} ä¿å­˜ {len(part_lines)} æ¡è§„åˆ™ â†’ {part_file}")
        print(f"å‰ 10 æ¡ç¤ºä¾‹ï¼š {part_lines[:10]}")
        part_files.append(part_file)
    return part_files

def dns_check(lines):
    resolver = dns.resolver.Resolver()
    valid = []
    total = len(lines)
    for i in range(0, total, DNS_BATCH_SIZE):
        batch = lines[i:i+DNS_BATCH_SIZE]
        batch_valid = []
        for rule in batch:
            domain = rule.lstrip("|").rstrip("^")
            try:
                resolver.resolve(domain)
                batch_valid.append(rule)
            except:
                pass
        valid.extend(batch_valid)
        print(f"âœ… å·²éªŒè¯ {min(i+DNS_BATCH_SIZE,total)}/{total} æ¡ï¼Œæœ¬æ‰¹æœ‰æ•ˆ {len(batch_valid)} æ¡")
        print(f"å‰ 10 æ¡è§„åˆ™ç¤ºä¾‹ï¼š {batch_valid[:10]}")
    return valid

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--update", action="store_true", help="æ›´æ–° urls.txt å¹¶åˆ‡ç‰‡")
    parser.add_argument("--part", type=int, help="æ‰‹åŠ¨éªŒè¯æŒ‡å®šåˆ†ç‰‡ 0~15")
    args = parser.parse_args()

    if args.update:
        lines = download_urls()
        split_urls(lines)
        return

    part_files = [os.path.join(TMP_DIR, f"part_{i+1:02}.txt") for i in range(NUM_PARTS)]

    if args.part is not None:
        idx = args.part
        if idx < 0 or idx >= NUM_PARTS:
            print("âŒ åˆ†ç‰‡ç´¢å¼•è¶…å‡ºèŒƒå›´")
            return
        part_files = [part_files[idx]]

    all_valid = []
    for part_file in part_files:
        with open(part_file, "r", encoding="utf-8") as f:
            lines = [l.strip() for l in f if l.strip()]
        print(f"â± å½“å‰å¤„ç†åˆ†ç‰‡ï¼š{part_file}, æ€»è§„åˆ™ {len(lines)} æ¡")
        print(f"å‰ 10 æ¡è§„åˆ™ç¤ºä¾‹ï¼š {lines[:10]}")
        valid = dns_check(lines)
        all_valid.extend(valid)

    # ä¿å­˜å…¨éƒ¨æœ‰æ•ˆè§„åˆ™
    valid_file = os.path.join(DIST_DIR, "blocklist_valid.txt")
    with open(valid_file, "w", encoding="utf-8") as f:
        f.write("\n".join(all_valid))
    print(f"ğŸ“‚ å·²ä¿å­˜ {len(all_valid)} æ¡æœ‰æ•ˆè§„åˆ™ â†’ {valid_file}")

if __name__ == "__main__":
    main()
